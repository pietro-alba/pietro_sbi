{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b54cc6f-ba95-4bc8-a4e6-87a724fb2f94",
   "metadata": {},
   "source": [
    "<h1>Running and saving multiple simulations</h1>\n",
    "<div class=\"text\">\n",
    "    In this notebook, I will explain how to create simulations of coeval cubes and save only the statistics of these coeval cubes.\n",
    "    <br>\n",
    "    There are two functions to create run these simulations:\n",
    "     <ul>\n",
    "      <li>psbi.create_batched_data_2() which saves the $\\ell^1$ and $\\ell^2$ summaries, and the astrophysical paramters</li>\n",
    "      <li>psbi.create_batched_data_0() which saves the statatistics PS, S1, S2, PS3d and the astrophysical parameters</li>\n",
    "     </ul> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232b8d79-8e26-4c2b-889b-f1e4198088a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/obs/pguidi/anaconda3/envs/sbi_21cmfast_env/lib/python3.9/site-packages/py21cmfast/_cfg.py:57: UserWarning: Your configuration file is out of date. Updating...\n",
      "  warnings.warn(\n",
      "/obs/pguidi/anaconda3/envs/sbi_21cmfast_env/lib/python3.9/site-packages/py21cmfast/_cfg.py:41: UserWarning: Your configuration file is out of date. Updating...\n",
      "  warnings.warn(\"Your configuration file is out of date. Updating...\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(1, os.path.abspath('../')) # Note that this line is useless with a regular pip installation of PyWST.\n",
    "import pietrosbi as psbi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f891555-ca5c-473b-b0da-000ca321d322",
   "metadata": {},
   "source": [
    "<h2>Function for the statistics PS, S1, S2, PS3d</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903f7dcc-bf7b-4a32-82ef-6b01baa2b48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/obs/pguidi/anaconda3/envs/sbi_21cmfast_env/lib/python3.9/site-packages/py21cmfast/_utils.py:400: UserWarning: The following parameters to FlagOptions are not supported: ['USE_VELS_AUX']\n",
      "  warnings.warn(\n",
      "/obs/pguidi/anaconda3/envs/sbi_21cmfast_env/lib/python3.9/site-packages/py21cmfast/_utils.py:815: UserWarning: Trying to remove array that isn't yet created: hires_vx\n",
      "  warnings.warn(f\"Trying to remove array that isn't yet created: {k}\")\n",
      "/obs/pguidi/anaconda3/envs/sbi_21cmfast_env/lib/python3.9/site-packages/py21cmfast/_utils.py:815: UserWarning: Trying to remove array that isn't yet created: hires_vy\n",
      "  warnings.warn(f\"Trying to remove array that isn't yet created: {k}\")\n",
      "/obs/pguidi/anaconda3/envs/sbi_21cmfast_env/lib/python3.9/site-packages/py21cmfast/_utils.py:815: UserWarning: Trying to remove array that isn't yet created: hires_vz\n",
      "  warnings.warn(f\"Trying to remove array that isn't yet created: {k}\")\n",
      "/obs/pguidi/anaconda3/envs/sbi_21cmfast_env/lib/python3.9/site-packages/py21cmfast/_utils.py:815: UserWarning: Trying to remove array that isn't yet created: hires_vx_2LPT\n",
      "  warnings.warn(f\"Trying to remove array that isn't yet created: {k}\")\n",
      "/obs/pguidi/anaconda3/envs/sbi_21cmfast_env/lib/python3.9/site-packages/py21cmfast/_utils.py:815: UserWarning: Trying to remove array that isn't yet created: hires_vy_2LPT\n",
      "  warnings.warn(f\"Trying to remove array that isn't yet created: {k}\")\n",
      "/obs/pguidi/anaconda3/envs/sbi_21cmfast_env/lib/python3.9/site-packages/py21cmfast/_utils.py:815: UserWarning: Trying to remove array that isn't yet created: hires_vz_2LPT\n",
      "  warnings.warn(f\"Trying to remove array that isn't yet created: {k}\")\n"
     ]
    }
   ],
   "source": [
    "# Number of bacthes for the simulations\n",
    "n_batches = 2\n",
    "\n",
    "# Number of simulation per batch\n",
    "n_per_batch = 2\n",
    "\n",
    "# So total number of simulations n = n_batches * n_per_batch\n",
    "\n",
    "# Redshif, number of pixels and dimension of the cube\n",
    "z = 9\n",
    "n_pixels = 32\n",
    "dim = 300\n",
    "\n",
    "# NUmber of bins for the statistics\n",
    "bins = 6\n",
    "\n",
    "# These three paramters are ignored since it doesn't calculate the ell summaries\n",
    "l1 = True\n",
    "l2 = True\n",
    "wavelet_type = 'morl'\n",
    "\n",
    "# Starting seed\n",
    "start_seed = 1\n",
    "\n",
    "# True: if you want to save the statistics. Remember to change the directory to the oneyou want\n",
    "# False: if you don't want to save the statistics\n",
    "save_files = False\n",
    "\n",
    "# This function doesn't return anything\n",
    "# If you want to anlayse the statistics, you have to first save the files\n",
    "# The cleaning of the 21cmfast-cache is done inside the function\n",
    "psbi.create_batched_data_0(n_batches = n_batches, \n",
    "                           n_per_batch = n_per_batch, \n",
    "                           z = z, \n",
    "                           n_pixels = n_pixels, \n",
    "                           dim = dim, \n",
    "                           bins = bins, \n",
    "                           l1 = l1, \n",
    "                           l2 = l2, \n",
    "                           wavelet_type = wavelet_type, \n",
    "                           start_seed = start_seed, \n",
    "                           save_files = save_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b72e14c-c18f-4465-81bb-e814c7d7a75f",
   "metadata": {},
   "source": [
    "<h2>Importing the .npy files with the statistics PS, S1, S2 and PS3d</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "845f89cb-e38e-495a-91cb-183dadd5c485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs. S1 has been loaded <class 'numpy.ndarray'> (32, 6)\n",
      "Obs. PS has been loaded <class 'numpy.ndarray'> (32, 6)\n",
      "Obs. PS3d has been loaded <class 'numpy.ndarray'> (6,)\n",
      "Obs. S2 has been loaded <class 'numpy.ndarray'> (32, 6, 6)\n",
      "Obs. param. has been loaded <class 'numpy.ndarray'> (2,)\n",
      "['/travail/pguidi/correct_data/data_summary_S1_1000_0.npy', '/travail/pguidi/correct_data/data_summary_S1_1000_1.npy', '/travail/pguidi/correct_data/data_summary_S1_1000_2.npy', '/travail/pguidi/correct_data/data_summary_S1_1000_3.npy', '/travail/pguidi/correct_data/data_summary_S1_1000_4.npy', '/travail/pguidi/correct_data/data_summary_S1_1000_5.npy', '/travail/pguidi/correct_data/data_summary_S1_1000_6.npy', '/travail/pguidi/correct_data/data_summary_S1_1000_7.npy', '/travail/pguidi/correct_data/data_summary_S1_1000_8.npy', '/travail/pguidi/correct_data/data_summary_S1_1000_9.npy']\n",
      "Simulated S1 have been loaded <class 'numpy.ndarray'> (1000, 32, 6)\n",
      "['/travail/pguidi/correct_data/data_summary_PS_1000_0.npy', '/travail/pguidi/correct_data/data_summary_PS_1000_1.npy', '/travail/pguidi/correct_data/data_summary_PS_1000_2.npy', '/travail/pguidi/correct_data/data_summary_PS_1000_3.npy', '/travail/pguidi/correct_data/data_summary_PS_1000_4.npy', '/travail/pguidi/correct_data/data_summary_PS_1000_5.npy', '/travail/pguidi/correct_data/data_summary_PS_1000_6.npy', '/travail/pguidi/correct_data/data_summary_PS_1000_7.npy', '/travail/pguidi/correct_data/data_summary_PS_1000_8.npy', '/travail/pguidi/correct_data/data_summary_PS_1000_9.npy']\n",
      "Simulated PS have been loaded <class 'numpy.ndarray'> (1000, 32, 6)\n",
      "['/travail/pguidi/correct_data/data_summary_PS3d_1000_0.npy', '/travail/pguidi/correct_data/data_summary_PS3d_1000_1.npy', '/travail/pguidi/correct_data/data_summary_PS3d_1000_2.npy', '/travail/pguidi/correct_data/data_summary_PS3d_1000_3.npy', '/travail/pguidi/correct_data/data_summary_PS3d_1000_4.npy', '/travail/pguidi/correct_data/data_summary_PS3d_1000_5.npy', '/travail/pguidi/correct_data/data_summary_PS3d_1000_6.npy', '/travail/pguidi/correct_data/data_summary_PS3d_1000_7.npy', '/travail/pguidi/correct_data/data_summary_PS3d_1000_8.npy', '/travail/pguidi/correct_data/data_summary_PS3d_1000_9.npy']\n",
      "Simulated PS3d have been loaded <class 'numpy.ndarray'> (1000, 6)\n",
      "['/travail/pguidi/correct_data/data_summary_S2_1000_0.npy', '/travail/pguidi/correct_data/data_summary_S2_1000_1.npy', '/travail/pguidi/correct_data/data_summary_S2_1000_2.npy', '/travail/pguidi/correct_data/data_summary_S2_1000_3.npy', '/travail/pguidi/correct_data/data_summary_S2_1000_4.npy', '/travail/pguidi/correct_data/data_summary_S2_1000_5.npy', '/travail/pguidi/correct_data/data_summary_S2_1000_6.npy', '/travail/pguidi/correct_data/data_summary_S2_1000_7.npy', '/travail/pguidi/correct_data/data_summary_S2_1000_8.npy', '/travail/pguidi/correct_data/data_summary_S2_1000_9.npy']\n",
      "Simulated S2 have been loaded <class 'numpy.ndarray'> (1000, 32, 6, 6)\n",
      "['/travail/pguidi/correct_data/param_list_1000_0.npy', '/travail/pguidi/correct_data/param_list_1000_1.npy', '/travail/pguidi/correct_data/param_list_1000_2.npy', '/travail/pguidi/correct_data/param_list_1000_3.npy', '/travail/pguidi/correct_data/param_list_1000_4.npy', '/travail/pguidi/correct_data/param_list_1000_5.npy', '/travail/pguidi/correct_data/param_list_1000_6.npy', '/travail/pguidi/correct_data/param_list_1000_7.npy', '/travail/pguidi/correct_data/param_list_1000_8.npy', '/travail/pguidi/correct_data/param_list_1000_9.npy']\n",
      "Simulated params have been loaded <class 'numpy.ndarray'> (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder with all the .npy files\n",
    "path_to_folder = '/travail/pguidi/correct_data/'\n",
    "\n",
    "# Loading the 'observation' and the true paramaters\n",
    "data_obs_S1 = np.load(path_to_folder + 'data_obs_S1_1000.npy')\n",
    "print('Obs. S1 has been loaded', type(data_obs_S1), data_obs_S1.shape)\n",
    "data_obs_PS = np.load(path_to_folder + 'data_obs_PS_1000.npy')\n",
    "print('Obs. PS has been loaded', type(data_obs_PS), data_obs_PS.shape)\n",
    "data_obs_PS3d = np.load(path_to_folder + 'data_obs_PS3d_1000.npy')\n",
    "print('Obs. PS3d has been loaded', type(data_obs_PS3d), data_obs_PS3d.shape)\n",
    "data_obs_S2 = np.load(path_to_folder + 'data_obs_S2_1000.npy')\n",
    "print('Obs. S2 has been loaded', type(data_obs_S2), data_obs_S2.shape)\n",
    "param_true = np.load(path_to_folder + 'param_true_1000.npy')[:2]\n",
    "print('Obs. param. has been loaded', type(param_true), param_true.shape)\n",
    "\n",
    "# Loading the simulated S1, PS, S2, PS3d and the list of parameters used in these simulations\n",
    "data_S1 = psbi.import_data_test(path_to_folder + 'data_summary_S1_1000_[0-9].npy')\n",
    "print('Simulated S1 have been loaded', type(data_S1), data_S1.shape)\n",
    "data_PS = psbi.import_data_test(path_to_folder + 'data_summary_PS_1000_[0-9].npy')\n",
    "print('Simulated PS have been loaded', type(data_PS), data_PS.shape)\n",
    "data_PS3d = psbi.import_data_test(path_to_folder + 'data_summary_PS3d_1000_[0-9].npy')\n",
    "print('Simulated PS3d have been loaded', type(data_PS3d), data_PS3d.shape)\n",
    "data_S2 = psbi.import_data_test(path_to_folder + 'data_summary_S2_1000_[0-9].npy')\n",
    "print('Simulated S2 have been loaded', type(data_S2), data_S2.shape)\n",
    "param_list = psbi.import_data_test(path_to_folder + 'param_list_1000_[0-9].npy')[:,:2]\n",
    "print('Simulated params have been loaded', type(param_list), param_list.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dbf2b92-5619-4976-a9b2-1f2feda88d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mesopsl3/home/pguidi/files_github/pietrosbi/import_data_S1_S2_PS_PS3d.py:103: RuntimeWarning: invalid value encountered in divide\n",
      "  data_S2_new = data_S2 / data_S1_rev\n",
      "/mesopsl3/home/pguidi/files_github/pietrosbi/import_data_S1_S2_PS_PS3d.py:104: RuntimeWarning: invalid value encountered in divide\n",
      "  data_S1_new = data_S1 / np.sqrt(data_PS)\n"
     ]
    }
   ],
   "source": [
    "# This function calculates the l1 and l2 summaries for the simulated PS, S1 and S2.\n",
    "# It also modifies the array from np.arrays with float64 values to torch.tensors with float32 values\n",
    "# Float32 is needed for torch.tensor\n",
    "l1l2_summary_PS, l1l2_summary_S1, l1l2_summary_S2, data_PS3d, param_list = psbi.l1l2_and_torchify_data(data_PS, \n",
    "                                                                                                       data_S1, \n",
    "                                                                                                       data_S2, \n",
    "                                                                                                       data_PS3d, \n",
    "                                                                                                       param_list,\n",
    "                                                                                                       n_pixels, \n",
    "                                                                                                       wavelet_type,\n",
    "                                                                                                       l1,\n",
    "                                                                                                       l2\n",
    "                                                                                                      )\n",
    "\n",
    "\n",
    "# This function will give a runtime warning due to a division by 0.\n",
    "# This happens during the normalization of slices where the brightness temperature is 0 everywhere,\n",
    "# so PS, S1 and S2 will be 0 and when I divide S1/PS I will basicallly have 0/0 = nan.\n",
    "# Inside that function I assign the value 0 to all the nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a832c680-74d6-496b-bf65-c9603ae3c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the l1 and l2 summaries for the 'observed' PS, S1 and S2.\n",
    "# It also modifies the array from np.arrays with float64 values to torch.tensors with float32 values\n",
    "# Float32 is needed for torch.tensor\n",
    "l1l2_summary_obs_PS, l1l2_summary_obs_S1, l1l2_summary_obs_S2, data_obs_PS3d, param_true = psbi.l1l2_and_torchify_obs_data(data_obs_PS, \n",
    "                                                                                                                           data_obs_S1, \n",
    "                                                                                                                           data_obs_S2, \n",
    "                                                                                                                           data_obs_PS3d, \n",
    "                                                                                                                           param_true,\n",
    "                                                                                                                           n_pixels,\n",
    "                                                                                                                           wavelet_type,\n",
    "                                                                                                                           l1, \n",
    "                                                                                                                           l2                                                                                                                          \n",
    "                                                                                                                          )\n",
    "\n",
    "# This function will sometimes give a runtime warning due to a division by 0.\n",
    "# This happens during the normalization of slices where the brightness temperature is 0 everywhere,\n",
    "# so PS, S1 and S2 will be 0 and when I divide S1/PS I will basicallly have 0/0 = nan.\n",
    "# Inside that function I assign the value 0 to all the nan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa42acd7-2055-458d-bb0e-6e540b75dfcd",
   "metadata": {},
   "source": [
    "<h2>Function for the $\\ell^1$ and $\\ell^2$ summaries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2c58ec-fbd9-47b7-97da-fafa4dbe3545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mesopsl3/home/pguidi/files_github/pietrosbi/pietro_wavelet_transforms.py:351: RuntimeWarning: invalid value encountered in divide\n",
      "  self.S2 =self.S2 / S1_rev[:,:,np.newaxis]\n",
      "/mesopsl3/home/pguidi/files_github/pietrosbi/pietro_wavelet_transforms.py:352: RuntimeWarning: invalid value encountered in divide\n",
      "  self.S1 = self.S1 / np.sqrt(self.PS)\n"
     ]
    }
   ],
   "source": [
    "# Number of bacthes for the simulations\n",
    "n_batches = 2\n",
    "\n",
    "# Number of simulation per batch\n",
    "n_per_batch = 2\n",
    "\n",
    "# So total number of simulations n = n_batches * n_per_batch\n",
    "\n",
    "# Redshif, number of pixels and dimension of the cube\n",
    "z = 9\n",
    "n_pixels = 32\n",
    "dim = 300\n",
    "\n",
    "# NUmber of bins for the statistics\n",
    "bins = 6\n",
    "\n",
    "# True if you want the l1 summary, otherwise False\n",
    "l1 = True\n",
    "\n",
    "# True if you want the l2 summary, otherwise False\n",
    "l2 = True\n",
    "\n",
    "# Type wavelet for the line of sight decomposition\n",
    "wavelet_type = 'morl'\n",
    "\n",
    "# Starting seed\n",
    "start_seed = 1\n",
    "\n",
    "# True: if you want to save the statistics. Remember to change the directory to the oneyou want\n",
    "# False: if you don't want to save the statistics\n",
    "save_files = False\n",
    "\n",
    "# This function doesn't return anything\n",
    "# If you want to anlayse the l1 and l2 summaries, you have to first save the files\n",
    "# The cleaning of the 21cmfast-cache is done inside the function\n",
    "psbi.create_batched_data_2(n_batches = n_batches, \n",
    "                           n_per_batch = n_per_batch, \n",
    "                           z = z, \n",
    "                           n_pixels = n_pixels, \n",
    "                           dim = dim, \n",
    "                           bins = bins, \n",
    "                           l1 = l1, \n",
    "                           l2 = l2, \n",
    "                           wavelet_type = wavelet_type, \n",
    "                           start_seed = start_seed, \n",
    "                           save_files = save_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf09118-abe2-4e24-a681-bb57e2cd7fca",
   "metadata": {},
   "source": [
    "<h2>Importing the .npy files with the $\\ell^1$ and $\\ell^2$ summaries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d96b9a2-6f88-4ddc-ad74-90825c71208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs. S1 has been loaded <class 'torch.Tensor'> torch.Size([60])\n",
      "Obs. PS has been loaded <class 'torch.Tensor'> torch.Size([60])\n",
      "Obs. PS3d has been loaded <class 'torch.Tensor'> torch.Size([6])\n",
      "Obs. S2 has been loaded <class 'torch.Tensor'> torch.Size([360])\n",
      "Obs. param. has been loaded <class 'torch.Tensor'> torch.Size([2])\n",
      "Simulated S1 have been loaded <class 'torch.Tensor'> torch.Size([1000, 60])\n",
      "Simulated PS have been loaded <class 'torch.Tensor'> torch.Size([1000, 60])\n",
      "Simulated PS3d have been loaded <class 'torch.Tensor'> torch.Size([1000, 6])\n",
      "Simulated S2 have been loaded <class 'torch.Tensor'> torch.Size([1000, 360])\n",
      "Simulated params have been loaded <class 'torch.Tensor'> torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder with the .npy files of the l1 and l2 summaries\n",
    "path_to_folder = '/travail/pguidi/data_for_sbi_l1l2/'\n",
    "\n",
    "# Importing the .npy files of the 'observed' data and the true parameters\n",
    "# This function also converts np.arrays with float64 to torch.tensor with float32\n",
    "data_obs_S1 = psbi.import_obs_l1l2(path_to_folder + 'data_obs_S1_l1l2_1000.npy')\n",
    "print('Obs. S1 has been loaded', type(data_obs_S1), data_obs_S1.shape)\n",
    "data_obs_PS = psbi.import_obs_l1l2(path_to_folder + 'data_obs_PS_l1l2_1000.npy')\n",
    "print('Obs. PS has been loaded', type(data_obs_PS), data_obs_PS.shape)\n",
    "data_obs_PS3d = psbi.import_obs_l1l2(path_to_folder + 'data_obs_PS3d_1000.npy')\n",
    "print('Obs. PS3d has been loaded', type(data_obs_PS3d), data_obs_PS3d.shape)\n",
    "data_obs_S2 = psbi.import_obs_l1l2(path_to_folder + 'data_obs_S2_l1l2_1000.npy')\n",
    "print('Obs. S2 has been loaded', type(data_obs_S2), data_obs_S2.shape)\n",
    "param_true = np.load(path_to_folder + 'param_true_1000.npy')[:2]\n",
    "param_true = psbi.torchify(param_true)\n",
    "print('Obs. param. has been loaded', type(param_true), param_true.shape)\n",
    "\n",
    "# Importing the .npy files of the simulated data and the list of parameters used for these simulations\n",
    "# This function also converts np.arrays with float64 to torch.tensor with float32\n",
    "data_S1 = psbi.import_data_l1l2(path_to_folder + 'data_summary_S1_*.npy')\n",
    "print('Simulated S1 have been loaded', type(data_S1), data_S1.shape)\n",
    "data_PS = psbi.import_data_l1l2(path_to_folder + 'data_summary_PS_*.npy')\n",
    "print('Simulated PS have been loaded', type(data_PS), data_PS.shape)\n",
    "data_PS3d = psbi.import_data_l1l2(path_to_folder + 'data_summary_PS3d_*.npy')\n",
    "print('Simulated PS3d have been loaded', type(data_PS3d), data_PS3d.shape)\n",
    "data_S2 = psbi.import_data_l1l2(path_to_folder + 'data_summary_S2_*.npy')\n",
    "print('Simulated S2 have been loaded', type(data_S2), data_S2.shape)\n",
    "param_list = psbi.import_data_l1l2(path_to_folder + 'param_list_*.npy')\n",
    "print('Simulated params have been loaded', type(param_list), param_list.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d6dd9c-8538-45ba-a553-7e5a8c2665ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
